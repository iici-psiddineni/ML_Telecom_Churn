{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Telecom Churn Case Study</font>\n",
    "* Institution: IIIT, Bangalore and UpGrad\n",
    "* Course: PG Diploma in Machine Lerning and AI March 2018\n",
    "* Date: 14-Aug-2018\n",
    "* Submitted by:\n",
    "    1. Pandinath Siddineni (ID- APFE187000194)\n",
    "    2. AKNR Chandra Sekhar (ID- APFE187000315)\n",
    "    3. Brajesh Kumar       (ID- APFE187000149)\n",
    "    4. Shweta Tiwari\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>PART 3: FEATURE REDUCTION USING LASSO</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load clean telecom data file\n",
    "master_df = pd.read_csv('telecom_churn_data_clean.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>fb7_1.0</th>\n",
       "      <th>fb8_0.0</th>\n",
       "      <th>fb8_1.0</th>\n",
       "      <th>total_rech_data_amt_6</th>\n",
       "      <th>total_rech_data_amt_7</th>\n",
       "      <th>total_rech_data_amt_8</th>\n",
       "      <th>churn</th>\n",
       "      <th>rech_days_left_6</th>\n",
       "      <th>rech_days_left_7</th>\n",
       "      <th>rech_days_left_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000701601</td>\n",
       "      <td>1069.18</td>\n",
       "      <td>1349.85</td>\n",
       "      <td>3171.48</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>567.16</td>\n",
       "      <td>325.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001524846</td>\n",
       "      <td>378.72</td>\n",
       "      <td>492.22</td>\n",
       "      <td>137.36</td>\n",
       "      <td>413.69</td>\n",
       "      <td>351.03</td>\n",
       "      <td>35.08</td>\n",
       "      <td>94.66</td>\n",
       "      <td>80.63</td>\n",
       "      <td>136.48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>354.00</td>\n",
       "      <td>207.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7002124215</td>\n",
       "      <td>514.45</td>\n",
       "      <td>597.75</td>\n",
       "      <td>637.76</td>\n",
       "      <td>102.41</td>\n",
       "      <td>132.11</td>\n",
       "      <td>85.14</td>\n",
       "      <td>757.93</td>\n",
       "      <td>896.68</td>\n",
       "      <td>983.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000887461</td>\n",
       "      <td>74.35</td>\n",
       "      <td>193.90</td>\n",
       "      <td>366.97</td>\n",
       "      <td>48.96</td>\n",
       "      <td>50.66</td>\n",
       "      <td>33.58</td>\n",
       "      <td>85.41</td>\n",
       "      <td>89.36</td>\n",
       "      <td>205.89</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>712.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000149764</td>\n",
       "      <td>977.02</td>\n",
       "      <td>2362.83</td>\n",
       "      <td>409.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5285.00</td>\n",
       "      <td>20424.00</td>\n",
       "      <td>455.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  arpu_6  arpu_7  arpu_8  onnet_mou_6  onnet_mou_7  \\\n",
       "0     7000701601 1069.18 1349.85 3171.48        57.84        54.68   \n",
       "1     7001524846  378.72  492.22  137.36       413.69       351.03   \n",
       "2     7002124215  514.45  597.75  637.76       102.41       132.11   \n",
       "3     7000887461   74.35  193.90  366.97        48.96        50.66   \n",
       "4     7000149764  977.02 2362.83  409.23         0.00         0.00   \n",
       "\n",
       "   onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8        ...         \\\n",
       "0        52.29        453.43        567.16        325.91        ...          \n",
       "1        35.08         94.66         80.63        136.48        ...          \n",
       "2        85.14        757.93        896.68        983.39        ...          \n",
       "3        33.58         85.41         89.36        205.89        ...          \n",
       "4         0.00          0.00          0.00          0.00        ...          \n",
       "\n",
       "   fb7_1.0  fb8_0.0  fb8_1.0  total_rech_data_amt_6  total_rech_data_amt_7  \\\n",
       "0        0        0        0                   0.00                   0.00   \n",
       "1        1        0        1                   0.00                 354.00   \n",
       "2        0        0        0                   0.00                   0.00   \n",
       "3        1        0        1                   0.00                 712.00   \n",
       "4        1        0        1                5285.00               20424.00   \n",
       "\n",
       "   total_rech_data_amt_8  churn  rech_days_left_6  rech_days_left_7  \\\n",
       "0                   0.00      1              3.00              6.00   \n",
       "1                 207.00      0              5.00              0.00   \n",
       "2                   0.00      0              0.00              0.00   \n",
       "3                 540.00      0             12.00             24.00   \n",
       "4                 455.00      0              0.00              1.00   \n",
       "\n",
       "   rech_days_left_8  \n",
       "0              5.00  \n",
       "1              1.00  \n",
       "2              0.00  \n",
       "3              7.00  \n",
       "4              5.00  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#dropping mobile number#droppi \n",
    "telecom=master_df.drop(['mobile_number'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extracting all feature vector\n",
    "feature=telecom.drop(['churn'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X, y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = telecom.drop(['churn'],axis=1)\n",
    "y = telecom['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28504, 142)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying standard scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28504, 87)\n",
      "[  0   1   3   8   9  10  11  12  13  14  15  18  22  24  25  26  34  37\n",
      "  38  39  40  41  45  47  48  49  50  52  53  57  58  59  60  64  65  66\n",
      "  67  68  70  78  79  80  81  82  83  84  85  86  87  88  89  91  92  93\n",
      "  95  96  97  98 100 101 102 103 104 106 107 108 109 110 111 112 113 115\n",
      " 116 117 118 120 121 125 129 132 134 135 136 138 139 140 141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkumar5\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "lsvc = LinearSVC(C=0.02, penalty=\"l1\", dual=False).fit(X,y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_lasso = model.transform(X)\n",
    "pos = model.get_support(indices=True)\n",
    " \n",
    "print(X_lasso.shape)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arpu_6', 'arpu_7', 'onnet_mou_6', 'offnet_mou_8', 'roam_ic_mou_6',\n",
       "       'roam_ic_mou_7', 'roam_ic_mou_8', 'roam_og_mou_6', 'roam_og_mou_7',\n",
       "       'roam_og_mou_8', 'loc_og_t2t_mou_6', 'loc_og_t2m_mou_6',\n",
       "       'loc_og_t2f_mou_7', 'loc_og_t2c_mou_6', 'loc_og_t2c_mou_7',\n",
       "       'loc_og_t2c_mou_8', 'std_og_t2m_mou_7', 'std_og_t2f_mou_7',\n",
       "       'std_og_t2f_mou_8', 'std_og_mou_6', 'std_og_mou_7', 'std_og_mou_8',\n",
       "       'spl_og_mou_6', 'spl_og_mou_8', 'og_others_6', 'og_others_7',\n",
       "       'og_others_8', 'total_og_mou_7', 'total_og_mou_8', 'loc_ic_t2m_mou_6',\n",
       "       'loc_ic_t2m_mou_7', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_6',\n",
       "       'loc_ic_mou_7', 'loc_ic_mou_8', 'std_ic_t2t_mou_6', 'std_ic_t2t_mou_7',\n",
       "       'std_ic_t2t_mou_8', 'std_ic_t2m_mou_7', 'total_ic_mou_6',\n",
       "       'total_ic_mou_7', 'total_ic_mou_8', 'spl_ic_mou_6', 'spl_ic_mou_7',\n",
       "       'spl_ic_mou_8', 'isd_ic_mou_6', 'isd_ic_mou_7', 'isd_ic_mou_8',\n",
       "       'ic_others_6', 'ic_others_7', 'ic_others_8', 'total_rech_num_7',\n",
       "       'total_rech_num_8', 'total_rech_amt_6', 'total_rech_amt_8',\n",
       "       'max_rech_amt_6', 'max_rech_amt_7', 'max_rech_amt_8',\n",
       "       'last_day_rch_amt_7', 'last_day_rch_amt_8', 'vol_2g_mb_6',\n",
       "       'vol_2g_mb_7', 'vol_2g_mb_8', 'vol_3g_mb_7', 'vol_3g_mb_8',\n",
       "       'monthly_2g_6', 'monthly_2g_7', 'monthly_2g_8', 'sachet_2g_6',\n",
       "       'sachet_2g_7', 'sachet_2g_8', 'monthly_3g_7', 'monthly_3g_8',\n",
       "       'sachet_3g_6', 'sachet_3g_7', 'aon', 'aug_vbc_3g', 'night6_1.0',\n",
       "       'night8_1.0', 'fb7_0.0', 'fb8_0.0', 'fb8_1.0', 'total_rech_data_amt_6',\n",
       "       'total_rech_data_amt_8', 'rech_days_left_6', 'rech_days_left_7',\n",
       "       'rech_days_left_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#feature vector for decision tree#feature \n",
    "feature.columns[pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying smote to balance the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53816, 87)\n",
      "(53816,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26908"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(kind = \"regular\")\n",
    "X_tr,y_tr = sm.fit_sample(X_lasso,y)\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "np.count_nonzero(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkumar5\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tr,y_tr, train_size=0.7,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37671, 87)\n",
      "(37671,)\n",
      "(16145, 87)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print (y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature space holds 28504 observations and 142 features\n",
      "Unique target labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature space holds %d observations and %d features\" % X.shape)\n",
    "print (\"Unique target labels:\", np.unique(y))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying random forest with default hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkumar5\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Importing random forest classifier from sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97      8096\n",
      "          1       0.96      0.97      0.97      8049\n",
      "\n",
      "avg / total       0.97      0.97      0.97     16145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7794  302]\n",
      " [ 261 7788]]\n"
     ]
    }
   ],
   "source": [
    "# Printing confusion matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9651285227624652\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(2, 20, 5)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 5)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0           0.33             0.01             0.84              0.84   \n",
       "1           0.91             0.01             0.91              0.92   \n",
       "2           1.31             0.01             0.95              0.98   \n",
       "3           1.60             0.02             0.96              0.99   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "0               2   {'max_depth': 2}                4               0.84   \n",
       "1               7   {'max_depth': 7}                3               0.91   \n",
       "2              12  {'max_depth': 12}                2               0.95   \n",
       "3              17  {'max_depth': 17}                1               0.96   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0                0.84               0.81       ...                      0.85   \n",
       "1                0.92               0.91       ...                      0.91   \n",
       "2                0.98               0.95       ...                      0.95   \n",
       "3                0.99               0.96       ...                      0.96   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0                0.84               0.85                0.85   \n",
       "1                0.91               0.90                0.91   \n",
       "2                0.97               0.94                0.98   \n",
       "3                0.99               0.95                0.99   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0               0.82                0.83          0.02            0.01   \n",
       "1               0.91                0.92          0.02            0.01   \n",
       "2               0.95                0.98          0.02            0.01   \n",
       "3               0.96                0.99          0.09            0.00   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0            0.02             0.01  \n",
       "1            0.00             0.00  \n",
       "2            0.00             0.00  \n",
       "3            0.00             0.00  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFXCAYAAAC7nNf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal max_features\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [4, 8, 14, 20, 24,28,32,36,40,44,48,52,56]}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(200, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [5, 10,20,30,40,50]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=200,\n",
    "                             max_features=10,\n",
    "                             n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
